# If you are not sure what all these fields mean, please refer our documentation here:
# https://evalai.readthedocs.io/en/latest/configuration.html
title: Optical Character Recognition (OCR) challenge
short_description: OCR Challenge
description: templates/description.html
evaluation_details: templates/evaluation_details.html
terms_and_conditions: templates/terms_and_conditions.html
image: ocr.png
submission_guidelines: templates/submission_guidelines.html
leaderboard_description: The leaderboard ranks participants based on their evaluation scores, highlighting the top performers.
evaluation_script: evaluation_script.zip
remote_evaluation: False
start_date: 2025-05-01 00:00:00
end_date: 2099-05-31 23:59:59
published: True
# allowed_email_domains: A list of domains allowed to participate in the challenge. Leave blank if everyone is allowed to participate. (e.g. ["domain1.com", "domain2.org", "domain3.in"] Participants with these email domains will only be allowed to participate.)
tags:
  - Optic-Character-Recognition-OCR
  - machine-learning
  - data-science
  - computer-vision
leaderboard:
  - id: 1
    schema:
      {
        "labels": ["CER", "WER", "Total"],
        "default_order_by": "Total",
        "metadata":
          {
            "Metric1":
              {
                "sort_ascending": True,
                "description": "Word Error Rate (WER) measures the percentage of words incorrectly transcribed.",
              },
            "Metric2":
              {
                "sort_ascending": True,
                "description": "Character Error Rate (CER) measures the percentage of characters incorrectly transcribed.",
              },
          },
      }

challenge_phases:
  - id: 1
    name: Dev Phase
    description: templates/challenge_phase_1_description.html
    leaderboard_public: True # Hide the leaderboard
    is_public: True # (a Boolean field that gives the flexibility to Challenge Hosts to either hide or show the challenge phase to participants. Default is False)
    challenge: 1
    is_active: True
    max_concurrent_submissions_allowed: 3
    allowed_email_ids: []
    disable_logs: False
    is_submission_public: True # True/False (a Boolean field that gives the flexibility to Challenge Hosts to either make the submissions by default public/private. Note that this will only work when the leaderboard_public property is set to true. Default is False)
    start_date: 2025-01-19 00:00:00
    end_date: 2025-03-23 00:00:00 # Set end date to the past if required
    test_annotation_file: annotations/test_annotations_devsplit.json
    codename: dev # if u change here make changes in evaluation script as well
    max_submissions_per_day: 5
    max_submissions_per_month: 50
    max_submissions: 50
    default_submission_meta_attributes:
      - name: method_name
        is_visible: True
      - name: method_description
        is_visible: True
      - name: project_url
        is_visible: True
      - name: publication_url
        is_visible: True
    submission_meta_attributes:
      - name: TextAttribute
        description: Sample
        type: text
        required: False
      - name: SingleOptionAttribute
        description: Sample
        type: radio
        options: ["A", "B", "C"]
      - name: MultipleChoiceAttribute
        description: Sample
        type: checkbox
        options: ["alpha", "beta", "gamma"]
      - name: TrueFalseField
        description: Sample
        type: boolean
        required: True
    is_restricted_to_select_one_submission: False
    is_partial_submission_evaluation_enabled: False
    # allowed_submission_file_types: ".json, .zip, .txt, .tsv, .gz, .csv, .h5, .npy, .npz"
    allowed_submission_file_types: ".json, .csv"
  - id: 2
    name: Test Phase
    description: templates/challenge_phase_2_description.html
    leaderboard_public: True
    is_public: True
    challenge: 2
    is_active: True
    max_concurrent_submissions_allowed: 3
    allowed_email_ids: []
    disable_logs: False
    is_submission_public: True
    start_date: 2019-01-01 00:00:00
    end_date: 2099-05-24 23:59:59
    test_annotation_file: annotations/test_annotations_testsplit.json
    codename: test
    max_submissions_per_day: 5
    max_submissions_per_month: 50
    max_submissions: 50
    default_submission_meta_attributes:
      - name: method_name
        is_visible: True
      - name: method_description
        is_visible: True
      - name: project_url
        is_visible: True
      - name: publication_url
        is_visible: True
    submission_meta_attributes:
      - name: TextAttribute
        description: Sample
        type: text
      - name: SingleOptionAttribute
        description: Sample
        type: radio
        options: ["A", "B", "C"]
      - name: MultipleChoiceAttribute
        description: Sample
        type: checkbox
        options: ["alpha", "beta", "gamma"]
      - name: TrueFalseField
        description: Sample
        type: boolean
    is_restricted_to_select_one_submission: False
    is_partial_submission_evaluation_enabled: False

dataset_splits:
  - id: 1
    name: Train Split
    codename: train_split
  - id: 2
    name: Test Split
    codename: test_split

# A challenge phase split is the relation between a challenge phase and dataset splits for a challenge with a many-to-many relation. This is used to set the privacy of submissions (public/private) to different dataset splits for different challenge phases.
challenge_phase_splits:
  - challenge_phase_id: 1
    leaderboard_id: 1
    dataset_split_id: 1
    visibility: 1
    leaderboard_decimal_precision: 2
    is_leaderboard_order_descending: True
    show_execution_time: True
    show_leaderboard_by_latest_submission: True
  - challenge_phase_id: 2
    leaderboard_id: 1
    dataset_split_id: 1
    visibility: 3
    leaderboard_decimal_precision: 2
    is_leaderboard_order_descending: True
    # showeceution_time: False
    show_execution_time: False
    show_leaderboard_by_latest_submission: False
  - challenge_phase_id: 2
    leaderboard_id: 1
    dataset_split_id: 2
    visibility: 1
    leaderboard_decimal_precision: 2
    is_leaderboard_order_descending: True
    show_execution_time: True
    show_leaderboard_by_latest_submission: True
